{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80d1d06-5d69-49cb-9ae5-b0902438242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from natasha import Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger, Doc\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efcc22-e975-4c5a-a899-16c67daeb52b",
   "metadata": {},
   "source": [
    "# Подгружаем все размеченные аспекты из файлов и сохраняем в памяти\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589d5229-dc7a-4ad6-a80a-36e40cf1cd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P.P.S.',\n",
       " 'TEST.',\n",
       " 'qrdweqfrwefwef.',\n",
       " 'test ничтожество полное эта рыба в кляре.',\n",
       " 'test.',\n",
       " 'Было бы гораздо лучше, будь преподаватель с каким то практическим опытом в бизнесе.',\n",
       " 'Было очень любопытно через увлечение фанфиками узнать что-то новое о литературоведении, написании текстов и сценариев.',\n",
       " 'В перерывах между занятиями можно поговорить на разные темы.',\n",
       " 'В рамках обучения конечно же!',\n",
       " 'В целом курс больше подходит для тех, кто интересуется фанфиками с точки зрения литературы, чем социологии.',\n",
       " 'В этом курсе прокачаете разговорные навыки.',\n",
       " 'ВНИМАНИЕ!',\n",
       " 'Вам интересна музыка и ее связь с литературой и историей?',\n",
       " 'Весь семестр изучали диалекты.',\n",
       " 'Внимание!',\n",
       " 'Возникнут сложности?',\n",
       " 'Вообщем требуется полное включение в работу.',\n",
       " 'Вы же учитесь.',\n",
       " 'Вы собираете команду среди аудитории или с уже готовой командой придумываете идею (сюжет, геймплей, игровой движок) для разработки игры, а затем разрабатываете её.',\n",
       " 'Главное - слушать.',\n",
       " 'Да!',\n",
       " 'Действительно заинтересовалась различными приемами в мире кино.',\n",
       " 'Для кого курс?',\n",
       " 'Для обучающихся на направлениях педагогики и психологии данный электив особенно полезен!.',\n",
       " 'Для педагогов-супер!',\n",
       " 'Для тех, кто хочет разобраться в восточном кино и понять его так как задумывал автор.',\n",
       " 'Довольно интересный предмет.',\n",
       " 'Довольно интересный электив, если вы любите компьютерные игры.',\n",
       " 'Другие преподаватели лишь могут вести этот предмет, а не преподавать.',\n",
       " 'Думаю, многих интересует, легко ли сдать предмет у этого преподавателя?',\n",
       " 'Если в какой-то степени любите историю, то будет интересно послушать истории и развитие библиотек.',\n",
       " 'Если вы не собираетесь прямо идти в разработку игр - скорее всего предмет полезным вам не будет.',\n",
       " 'Если ты педагог, то идти не советую.',\n",
       " 'Забавная дисциплина, в своём роде скорее \"\"Философия компьютерных игр\"\" нежели оригинальное название.',\n",
       " 'Занимаетесь вы по учебнику, его нужно будет взять в библиотеке.',\n",
       " 'Занятия посещать нужно.',\n",
       " 'Занятия проходили в очень приятной обстановке.',\n",
       " 'Занятия проходят быстро и интересно.',\n",
       " 'Занятия проходят интересно, пользу переоценить сложно.',\n",
       " 'Здесь все зависит от стремлений и интересов студентов.. Очень интересно слушать лекции.',\n",
       " 'Здесь вы сможете обсудить все любимые произведения (современные, ужасы, детективы, фанфики, сериалы), найти для себя что-то новое, познакомиться с очень интересными книжками.',\n",
       " 'Здесь к играм относятся не как к тому, что было и остается продуктом для развлечения, а как к целостной картине, которую интересно разбирать на составляющие и анализировать их.',\n",
       " 'Иногда преподавательница задает вопросы для всей группы.',\n",
       " 'История и философия компьютерных игр - вот как можно описать этот предмет.',\n",
       " 'КОМИССИЮ ПО ЭЛЕКТИВУ.',\n",
       " 'Кайфы ловлю.',\n",
       " 'Как быть на коллоквиуме решать вам, но, по-моему мнению, лучше играть по своим правилам, чем по правилам преподавателя.. Описываю впечатления от электива с позиции человека, который редко играет в игры, но смотрит летсплеи и интересуется игровой индустрией.',\n",
       " 'Как незрячей студентке, мне было комфортно изучать дисциплину.',\n",
       " 'Круто.',\n",
       " 'Кстати!!!',\n",
       " 'Курс в этом деле будет скорее помехой.',\n",
       " 'Курс могу рекомендовать на весенний период обучения.',\n",
       " 'Курс очень понравился!',\n",
       " 'Мне нравится её подход к студентам.',\n",
       " 'Мне, как девушке с не особо большим игровым опытом, очень полезно и интересно рассматривать игры с другой точки зрения, я узнала для себя много нового.',\n",
       " 'Многого от студентов не требуется.',\n",
       " 'Многому научилась и теперь применяю в учебе.',\n",
       " 'Можно задавать вопросы, если что-то не получается.',\n",
       " 'Можно написать и прочитать текст о том, чем хочется поделиться.',\n",
       " 'НЕИЗВЕСТНО.',\n",
       " 'НО!',\n",
       " 'На лекциях рассказывают особенности периода, литературы того времени, часто бывает немного нудновато.',\n",
       " 'На парах затрагиваются вопросы о смысле, который вложен в игры.',\n",
       " 'Нагрузка не сказать, чтобы прям большая, но работать и в первую очередь думать на занятиях всех таки нужно.',\n",
       " 'Наконец-то научилась смотреть фильмы!.',\n",
       " 'Не страшно сказать какую-то глупость,',\n",
       " 'Нестрашно!',\n",
       " 'Ну и главное!',\n",
       " 'Нужно будет потратиться на материалы для занятий.',\n",
       " 'Обсуждения ведутся примерно в том же ключе.',\n",
       " 'Обучение проходило в рамках программы Neobook.',\n",
       " 'Однако на нем вы узнаете не только историю игр, но и посмотрите на них с точки зрения исследователя.',\n",
       " 'Одни из основных преимуществ учебного курса - проектный подход к обучению и практико-ориентированность.',\n",
       " 'Однозначно \"мастхэв\")).',\n",
       " 'Ответы есть в лекциях и в интернете.',\n",
       " 'Отличный курс для базового изучения frontend разработки.',\n",
       " 'Отличный курс!',\n",
       " 'Пишите рецензии и тд.',\n",
       " 'Плюсы:',\n",
       " 'Полное несоответствие название и содержания.',\n",
       " 'Понравился курс!',\n",
       " 'После мы много что смотрели',\n",
       " 'Преподаётся и теория, и практика выступлений.',\n",
       " 'Приглашают на занятия людей, занимающихся бизнесом.',\n",
       " 'Придётся поработать.',\n",
       " 'Присутствие на парах и выполнение работ необходимо.',\n",
       " 'Присутствовали на интернет-конференциях, после чего проводили активные дискуссии.',\n",
       " 'Проверено на практике.',\n",
       " 'Проверочный отзыв.',\n",
       " 'Процесс обучения представляет собой круглый стол с преподом, который разговаривает на приближенные к теме занятия топики.',\n",
       " 'РЕКОМЕНДУЮ!!!!!.',\n",
       " 'РЕКОМЕНДУЮ!.',\n",
       " 'Разбирали жанры произведений, составляли актантную схему.',\n",
       " 'Разобрался.',\n",
       " 'Рассказывали как игры стали такими какими они есть сейчас, но как-то не до конца... Лично мне электив вообще не понравился, я думала, что мы будем грамотно анализировать игры (не только со стороны сюжета и механик, но и лор, техническую составляющую геймдева, чем эти игры цепляют и т.д.), чтобы эти знания в будущем помогли их создавать, к примеру.',\n",
       " 'Сам урок тоже зачастую тянулся долго, так как в одном классе собрались люди с разной подготовкой ин.яз.',\n",
       " 'Сексист.',\n",
       " 'Собираемся еще группой посетить тот район с преподавателем.',\n",
       " 'Советую !.',\n",
       " 'Советую!!.',\n",
       " 'Советую!.',\n",
       " 'Студенты выполняют задания так, как поняли и привыкли.',\n",
       " 'Также разбираются чувства учителей, и влияние их убеждений на своих учеников.',\n",
       " 'Тест финальный!.',\n",
       " 'Тест хороший.',\n",
       " 'Тестировочный тест.',\n",
       " 'Ужас!.',\n",
       " 'Узнали о педагогической технике, работали над ораторским мастерством, что очень важно для учителя, проводили фрагменты своих первых уроков.',\n",
       " 'Уметь оперировать понятиями .',\n",
       " 'Ученье-свет.. test.',\n",
       " 'Читали - обсуждали.',\n",
       " 'Читать то, что ты написал не всегда обязательно.',\n",
       " 'Что по субъективной оценке?',\n",
       " 'Электив может вернуть желание читать художественную литературу, если вы когда-то забросили это.',\n",
       " 'Электив очень понравился, обсуждали книги и сериалы.',\n",
       " 'Электив подойдет для тех, кто любит литературу, искусство, кино и так далее.',\n",
       " 'Элективный курс позволяет получить знания в области литературы, но насколько эти знания пригодятся где-то на практике, я не знаю.',\n",
       " 'Этот курс проходит в рамках НИУ ВШЭ.',\n",
       " 'Этот разбор научил не просто смотреть кино, а замечать важные моменты',\n",
       " 'Этот электив подойдет всем студентам разных направлений.',\n",
       " 'Я узнала столько нового о мире фанфикшн, о литературе и роли автора, да и еще много чего.',\n",
       " 'Я учусь на факультете биологии.',\n",
       " 'бб.',\n",
       " 'выаываыва.',\n",
       " 'для новелл.',\n",
       " 'духота *******.',\n",
       " 'задания.',\n",
       " 'имба.',\n",
       " 'йцкайцкац.',\n",
       " 'карты и т.д.).',\n",
       " 'на паре.',\n",
       " 'синхронизация!.',\n",
       " 'удар!',\n",
       " 'факе.',\n",
       " 'штучка!',\n",
       " 'ыпаавып.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIRECTORY = Path(\"../data/otzyvus-annotated/\")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "# Предварительно удаляем расщирение .txt\n",
    "aspect_file_names = [\n",
    "    f[:-4]\n",
    "        for f\n",
    "        in listdir(DATA_DIRECTORY)\n",
    "        if isfile(DATA_DIRECTORY / f) and \".txt\" in f\n",
    "]\n",
    "\n",
    "# Объект аспект - массив предложений\n",
    "actual_aspects_sentences = {}\n",
    "# Список всех уникальных предложений\n",
    "all_aspects_senteces = []\n",
    "for file_name in aspect_file_names:\n",
    "    with open(DATA_DIRECTORY / (file_name + \".txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        actual_aspects_sentences[file_name] = set(\n",
    "            filter(\n",
    "                lambda string: len(string) > 0 and string[0].isalpha(),\n",
    "                f.read().split('\\n')\n",
    "            )\n",
    "        )\n",
    "        all_aspects_senteces += actual_aspects_sentences[file_name]\n",
    "\n",
    "all_aspects_senteces = list(set(all_aspects_senteces))\n",
    "actual_aspects_sentences.pop(\"мусор\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95202cb-0b55-4ac0-8a98-9bc51d03bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aspects():\n",
    "    return list(actual_aspects_sentences.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce967d6e-512d-4e4b-a9d4-9e35142fdab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    # Убираем ссылки\n",
    "    clean = re.sub(u'(http|ftp|https):\\/\\/[^ ]+', '', text)\n",
    "    # Убираем все неалфавитные символы кроме дефиса и апострофа\n",
    "    clean = re.sub(u'[^а-я^А-Я^\\w^\\-^\\']', ' ', clean)\n",
    "    # Убираем тире\n",
    "    clean = re.sub(u' - ', ' ', clean)\n",
    "    # Убираем дубликаты пробелов\n",
    "    clean = re.sub(u'\\s+', ' ', clean)\n",
    "    # Убираем пробелы в начале и в конце строки\n",
    "    clean = clean.strip().lower()\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d5b5da-4294-437f-ac05-e783e10d7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethodSubstring():\n",
    "    dictionary = {\n",
    "        \"материал информация\": [\"материал\"],\n",
    "        \"домашняя работа\": [\"домашняя работа\"],\n",
    "        \"зачёт\": [\"зачет\"],\n",
    "        \"фильмы\": [\"фильм\", \"кино\"],\n",
    "        \"презентации\": [\"презентация\"],\n",
    "        \"онлайн-курс\": [\"онлайн-курс\"],\n",
    "        \"видео-уроки\": [\"видео-урок\", \"видеоурок\"],\n",
    "        \"преподаватель\": [\"преподаватель\", \"препод\"],\n",
    "        \"выступления\": [\"выступление\"],\n",
    "        \"литература\": [\"литература\", \"книга\"],\n",
    "        \"тесты\": [\"тест\"],\n",
    "        \"практики семинары\": [\"практика\"],\n",
    "        \"доклады\": [\"доклад\"],\n",
    "        \"задания задачи\": [\"задание\"],\n",
    "        \"баллы\": [\"балл\", \"оценка\"],\n",
    "        \"эссе\": [\"эссе\"],\n",
    "        \"проекты\": [\"проект\"],\n",
    "        \"игры\" : [\"игра\"],\n",
    "        \"лекции\": [\"лекция\"],\n",
    "    }\n",
    "\n",
    "    def set_aspects(self, aspects_list=None):\n",
    "        if aspects_list is not None:\n",
    "            self.aspects_list = aspects_list\n",
    "        else:\n",
    "            self.aspects_list = load_aspects()\n",
    "\n",
    "    def __init__(self):\n",
    "        self.set_aspects(None)\n",
    "\n",
    "    def find_aspects(self, sentence: str):\n",
    "        aspects = []\n",
    "        # Очистка\n",
    "        sentence_words = clean_text(sentence).split(\" \")\n",
    "        # Лемматизация\n",
    "        doc = Doc(sentence)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "\n",
    "        for token in doc.tokens: \n",
    "            token.lemmatize(morph_vocab)\n",
    "        \n",
    "        lemmatized = ' '.join(token.lemma for token in doc.tokens)\n",
    "        \n",
    "        for aspect in self.aspects_list:\n",
    "            for word in self.dictionary[aspect]:\n",
    "                if word in lemmatized:\n",
    "                    aspects.append(aspect)\n",
    "        return aspects\n",
    "\n",
    "    def process(self, text: str):\n",
    "        return self.find_aspects(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "445b263d-cd19-4067-96a0-8d736eff99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethodSimilarity():\n",
    "\n",
    "    def transformers_tokenizer(self, sentence: str) -> torch.Tensor:\n",
    "        # tokens = self.transformers_auto_tokenizer(sentence, return_tensors='pt')\n",
    "        # vector = self.transformers_model(**tokens)[0].detach().squeeze()\n",
    "        # return torch.mean(vector, dim=0).numpy()\n",
    "        return self.model.encode(sentence, convert_to_tensor=True)\n",
    "\n",
    "    def set_aspects(self, aspects_list=None):\n",
    "        if aspects_list is not None:\n",
    "            self.aspects_list = aspects_list\n",
    "        else:\n",
    "            self.aspects_list = load_aspects()\n",
    "\n",
    "    def __init__(self, tokenizer=\"distiluse\", min_similarity = 0.5):\n",
    "        self.set_aspects(None)\n",
    "        self.aspects_list = load_aspects()\n",
    "        self.min_similarity = min_similarity\n",
    "        if tokenizer == \"distiluse\":\n",
    "            self.tokenizer = self.transformers_tokenizer\n",
    "            # self.transformers_auto_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "            # self.transformers_model = AutoModel.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "            self.model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "        elif tokenizer == \"sbert-pq\":\n",
    "            self.tokenizer = self.transformers_tokenizer\n",
    "            # self.transformers_auto_tokenizer = AutoTokenizer.from_pretrained(\"inkoziev/sbert_pq\")\n",
    "            # self.transformers_model = AutoModel.from_pretrained(\"inkoziev/sbert_pq\")\n",
    "            self.model = SentenceTransformer(\"inkoziev/sbert_pq\")\n",
    "        else:\n",
    "            self.tokenizer = None\n",
    "            raise Exception(\"Invalid tokenizer.\")\n",
    "        self.cosine_similarity = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "    # def calc_similarity(self, vector1, vector2):\n",
    "    #     return np.dot(vector1, vector2) / \\\n",
    "    #            (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "    def process(self, text: str):\n",
    "        aspects = []\n",
    "        # Схожесть\n",
    "        sentence_vector = self.tokenizer(text)\n",
    "        similarities = [(aspect, self.cosine_similarity(self.tokenizer(aspect), sentence_vector))\n",
    "                          for aspect in self.aspects_list]\n",
    "        for similarity in similarities:\n",
    "            if similarity[1] > self.min_similarity:\n",
    "                aspects.append(similarity[0])\n",
    "        return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d154d54d-ae45-4fe2-bb74-c0cf78030c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethodNLI():\n",
    "\n",
    "    def set_aspects(self, aspects_list=None):\n",
    "        if aspects_list is not None:\n",
    "            self.aspects_list = aspects_list\n",
    "        else:\n",
    "            self.aspects_list = load_aspects()\n",
    "        # self.prompts = self.aspects_list\n",
    "        self.prompts = list(map(lambda w: \"Я сказал о \" + w, self.aspects_list))\n",
    "\n",
    "    def __init__(self, tokenizer=\"distiluse\", min_similarity = 0.5):\n",
    "        self.set_aspects(None)\n",
    "        self.min_similarity = min_similarity\n",
    "        model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "        if torch.cuda.is_available():\n",
    "            self.model.cuda()\n",
    "\n",
    "    def predict_zero_shot(self, text, label_texts, label='entailment', normalize=False):\n",
    "        label_texts\n",
    "        tokens = self.tokenizer([text] * len(label_texts), label_texts, truncation=True, return_tensors='pt', padding=True)\n",
    "        with torch.inference_mode():\n",
    "            result = torch.softmax(self.model(**tokens.to(self.model.device)).logits, -1)\n",
    "        proba = result[:, self.model.config.label2id[label]].cpu().numpy()\n",
    "        if normalize:\n",
    "            proba /= sum(proba)\n",
    "        return proba\n",
    "\n",
    "    def process(self, sentence: str):\n",
    "        aspects = []\n",
    "        similarities = self.predict_zero_shot(sentence, self.prompts)\n",
    "        for similarity, aspect in zip(similarities, self.aspects_list):\n",
    "            # print(f\"sim: {similarity} aspect: {aspect}\") DEBUG\n",
    "            if similarity > self.min_similarity:\n",
    "                aspects.append(aspect)\n",
    "        return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "072dfd00-e199-44bc-b958-7ece7b26c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_substring = MethodSubstring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f447c347-9a69-4fc7-b68f-9b3d0437754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_similarity = MethodSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be29db1-d018-4d86-8707-fd9ee7baabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_nli = MethodNLI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b336550b-7c1c-4100-a01e-fdfafadf26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIRECTORY = Path(\"../output/test-search-accuracy-reports\")\n",
    "REPORTS_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_report(method):\n",
    "    y_expected = []\n",
    "    y_predicted = []\n",
    "\n",
    "    for sentence in tqdm(all_aspects_senteces):\n",
    "        y_expected.append(\n",
    "            [\n",
    "                aspect\n",
    "                for aspect in actual_aspects_sentences\n",
    "                if sentence in actual_aspects_sentences[aspect]\n",
    "            ]\n",
    "        )\n",
    "        y_predicted.append(method.process(sentence))\n",
    "        # print(y_predicted) # DEBUG\n",
    "\n",
    "    y_expected = MultiLabelBinarizer(classes=list(actual_aspects_sentences)).fit_transform(y_expected)\n",
    "    y_predicted = MultiLabelBinarizer(classes=list(actual_aspects_sentences)).fit_transform(y_predicted)\n",
    "        \n",
    "    report = classification_report(y_expected, y_predicted, target_names=list(actual_aspects_sentences), output_dict=True)\n",
    "    return report\n",
    "\n",
    "def save_report(report, name):\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "# set precision for all numeric values to 2\n",
    "    df[['precision', 'recall', 'f1-score']] = df[['precision', 'recall', 'f1-score']].applymap(lambda x: round(x, 2) if isinstance(x, float) else x)\n",
    "\n",
    "    df.to_csv(REPORTS_DIRECTORY / (\"report_\" + name + \".csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92552d1-c9a7-487d-86fa-98fccc3d419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating substring method accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1114/1114 [00:05<00:00, 192.05it/s]\n",
      "/home/danil/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danil/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danil/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danil/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/tmp/ipykernel_3918/1810607091.py:28: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['precision', 'recall', 'f1-score']] = df[['precision', 'recall', 'f1-score']].applymap(lambda x: round(x, 2) if isinstance(x, float) else x)\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating substring method accuracy...\")\n",
    "report_substring = make_report(search_substring)\n",
    "save_report(report_substring, \"substring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3e8eb22-fb24-4cc2-909c-9b9f71e24a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarity method accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████████████                                                                                                                                                                                | 114/1114 [00:17<02:31,  6.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating similarity method accuracy...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m search_similarity\u001b[38;5;241m.\u001b[39mmin_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m----> 3\u001b[0m report_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mmake_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_similarity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m save_report(report_similarity, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m, in \u001b[0;36mmake_report\u001b[0;34m(method)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m tqdm(all_aspects_senteces):\n\u001b[1;32m      9\u001b[0m     y_expected\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     10\u001b[0m         [\n\u001b[1;32m     11\u001b[0m             aspect\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         ]\n\u001b[1;32m     15\u001b[0m     )\n\u001b[0;32m---> 16\u001b[0m     y_predicted\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# print(y_predicted) # DEBUG\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y_expected \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer(classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(actual_aspects_sentences))\u001b[38;5;241m.\u001b[39mfit_transform(y_expected)\n",
      "Cell \u001b[0;32mIn[20], line 42\u001b[0m, in \u001b[0;36mMethodSimilarity.process\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Схожесть\u001b[39;00m\n\u001b[1;32m     41\u001b[0m sentence_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text)\n\u001b[0;32m---> 42\u001b[0m similarities \u001b[38;5;241m=\u001b[39m [(aspect, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosine_similarity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(aspect), sentence_vector))\n\u001b[1;32m     43\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m aspect \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maspects_list]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m similarity \u001b[38;5;129;01min\u001b[39;00m similarities:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m similarity[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_similarity:\n",
      "Cell \u001b[0;32mIn[20], line 42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Схожесть\u001b[39;00m\n\u001b[1;32m     41\u001b[0m sentence_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text)\n\u001b[0;32m---> 42\u001b[0m similarities \u001b[38;5;241m=\u001b[39m [(aspect, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosine_similarity(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43maspect\u001b[49m\u001b[43m)\u001b[49m, sentence_vector))\n\u001b[1;32m     43\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m aspect \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maspects_list]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m similarity \u001b[38;5;129;01min\u001b[39;00m similarities:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m similarity[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_similarity:\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mMethodSimilarity.transformers_tokenizer\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransformers_tokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# tokens = self.transformers_auto_tokenizer(sentence, return_tensors='pt')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# vector = self.transformers_model(**tokens)[0].detach().squeeze()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# return torch.mean(vector, dim=0).numpy()\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:344\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    347\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_length(sen) \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:801\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m--> 801\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m    802\u001b[0m             module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/abas-study-feedbacks-research-KcRJMMgI-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:2283\u001b[0m, in \u001b[0;36mModule.children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchildren\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over immediate children modules.\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \n\u001b[1;32m   2280\u001b[0m \u001b[38;5;124;03m    Yields:\u001b[39;00m\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;124;03m        Module: a child module\u001b[39;00m\n\u001b[1;32m   2282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2283\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2284\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m module\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Calculating similarity method accuracy...\")\n",
    "search_similarity.min_similarity = 0.5\n",
    "report_similarity = make_report(search_similarity)\n",
    "save_report(report_similarity, \"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2ecdf-84dc-4248-a5a2-37d8b3679670",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating NLI method accuracy...\")\n",
    "search_nli.min_similarity = 0.5\n",
    "report_nli = make_report(search_nli)\n",
    "save_report(report_nli, \"nli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867fd70-8191-4854-9651-b0aeb5a0e9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
