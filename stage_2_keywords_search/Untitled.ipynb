{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24abca3-0ac8-42d7-af71-573357ee60b4",
   "metadata": {},
   "source": [
    "# Подгружаем тестовый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6baaf1-33f8-45df-ae4b-bdf75af10531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Отличный электив, если хочешь начать учить нем...</td>\n",
       "      <td>фильмы</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Данный электив я выбрал потому, что моя мать с...</td>\n",
       "      <td>материал__информация__темы</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Отличный электив, если хочешь начать учить нем...</td>\n",
       "      <td>эссе</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Интересный электив, очень многое узнаете об ис...</td>\n",
       "      <td>тесты</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Очень интересный электив, направленный на укре...</td>\n",
       "      <td>онлайн-курс</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>Из пюсов могу выделить то, что преподаватель в...</td>\n",
       "      <td>баллы__оценки</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>Дмитрий Евгеньевич действительно очень хороший...</td>\n",
       "      <td>выступления</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>В целом, было несложно закрыть электив, если б...</td>\n",
       "      <td>материал__информация__темы</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>Скучный электив, лекции абсолютно не интересно...</td>\n",
       "      <td>тесты</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>Скучный электив, лекции абсолютно не интересно...</td>\n",
       "      <td>зачет__экзамен</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2375 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Отличный электив, если хочешь начать учить нем...   \n",
       "1     Данный электив я выбрал потому, что моя мать с...   \n",
       "2     Отличный электив, если хочешь начать учить нем...   \n",
       "3     Интересный электив, очень многое узнаете об ис...   \n",
       "4     Очень интересный электив, направленный на укре...   \n",
       "...                                                 ...   \n",
       "2370  Из пюсов могу выделить то, что преподаватель в...   \n",
       "2371  Дмитрий Евгеньевич действительно очень хороший...   \n",
       "2372  В целом, было несложно закрыть электив, если б...   \n",
       "2373  Скучный электив, лекции абсолютно не интересно...   \n",
       "2374  Скучный электив, лекции абсолютно не интересно...   \n",
       "\n",
       "                          aspect  label  \n",
       "0                         фильмы      0  \n",
       "1     материал__информация__темы      0  \n",
       "2                           эссе      0  \n",
       "3                          тесты      0  \n",
       "4                    онлайн-курс      0  \n",
       "...                          ...    ...  \n",
       "2370               баллы__оценки      3  \n",
       "2371                 выступления      3  \n",
       "2372  материал__информация__темы      3  \n",
       "2373                       тесты      3  \n",
       "2374              зачет__экзамен      3  \n",
       "\n",
       "[2375 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_PATH = Path(\"../data/datasets/valid_pairs.csv\")\n",
    "\n",
    "dataset = pd.read_csv(DATASET_PATH, sep=\",\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9494b44-350d-49da-a278-68b8aca2e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = list(dataset['aspect'].unique())\n",
    "readable_aspects = [ s.replace(\"__\", \", \").capitalize() for s in aspects ]\n",
    "readable_aspect_to_aspect = {}\n",
    "aspect_to_readable_aspect = {}\n",
    "for a, b in zip(aspects, readable_aspects):\n",
    "    readable_aspect_to_aspect[b] = a\n",
    "    aspect_to_readable_aspect[a] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ba932a-72ba-4e27-8d9c-8e13379ec5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Фильмы': 'фильмы',\n",
       " 'Материал, информация, темы': 'материал__информация__темы',\n",
       " 'Эссе': 'эссе',\n",
       " 'Тесты': 'тесты',\n",
       " 'Онлайн-курс': 'онлайн-курс',\n",
       " 'Игры, интерактивность': 'игры__интерактивность',\n",
       " 'Презентации': 'презентации',\n",
       " 'Домашняя работа': 'домашняя работа',\n",
       " 'Доклады': 'доклады',\n",
       " 'Лекции': 'лекции',\n",
       " 'Задания, задачи': 'задания__задачи',\n",
       " 'Литература, учебники': 'литература__учебники',\n",
       " 'Зачет, экзамен': 'зачет__экзамен',\n",
       " 'Проекты': 'проекты',\n",
       " 'Видео-уроки': 'видео-уроки',\n",
       " 'Выступления': 'выступления',\n",
       " 'Практики, семинары': 'практики__семинары',\n",
       " 'Преподаватель': 'преподаватель',\n",
       " 'Баллы, оценки': 'баллы__оценки'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readable_aspect_to_aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac5ef8-3eba-4504-877d-03eb4378be94",
   "metadata": {},
   "source": [
    "# Поиск аспектов на основе NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a571fd28-7f84-40ea-9493-4371aadc34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "class MethodSimilarity():\n",
    "\n",
    "    def transformers_tokenizer(self, sentence: str) -> torch.Tensor:\n",
    "        \n",
    "        tokens = self.transformers_auto_tokenizer(sentence, return_tensors='pt')\n",
    "        vector = self.transformers_model(**tokens)[0].detach().squeeze()\n",
    "        return torch.mean(vector, dim=0).numpy()\n",
    "        # return self.model.encode(sentence, convert_to_tensor=True)\n",
    "\n",
    "    def set_aspects(self, aspects_list=None):\n",
    "        if aspects_list is not None:\n",
    "            self.aspects_list = aspects_list\n",
    "        else:\n",
    "            self.aspects_list = readable_aspects\n",
    "\n",
    "    def __init__(self, tokenizer=\"distiluse\", min_similarity = 0.3):\n",
    "        self.set_aspects(None)\n",
    "        self.aspects_list = readable_aspects\n",
    "        self.min_similarity = min_similarity\n",
    "        if tokenizer == \"distiluse\":\n",
    "            self.tokenizer = self.transformers_tokenizer\n",
    "    \n",
    "            self.transformers_auto_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "            self.transformers_model = AutoModel.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "            # self.model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "        elif tokenizer == \"sbert-pq\":\n",
    "            self.tokenizer = self.transformers_tokenizer\n",
    "            \n",
    "            self.transformers_auto_tokenizer = AutoTokenizer.from_pretrained(\"inkoziev/sbert_pq\")\n",
    "            self.transformers_model = AutoModel.from_pretrained(\"inkoziev/sbert_pq\")\n",
    "            # self.model = SentenceTransformer(\"inkoziev/sbert_pq\")\n",
    "        elif tokenizer == \"deberta\":\n",
    "            self.tokenizer = self.transformers_tokenizer\n",
    "            \n",
    "            self.transformers_auto_tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\")\n",
    "            self.transformers_model = AutoModel.from_pretrained(\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\")\n",
    "            # self.model = SentenceTransformer(\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\")\n",
    "        else:\n",
    "            self.tokenizer = None\n",
    "            raise Exception(\"Invalid tokenizer.\")\n",
    "        \n",
    "        self.cosine_similarity = self.calc_similarity\n",
    "        # self.cosine_similarity = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "    def calc_similarity(self, vector1, vector2):\n",
    "        return np.dot(vector1, vector2) / \\\n",
    "               (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "    def process(self, text: str):\n",
    "        aspects = []\n",
    "        # Схожесть\n",
    "        sentence_vector = self.tokenizer(text)\n",
    "        similarities = [(aspect, self.cosine_similarity(self.tokenizer(aspect), sentence_vector))\n",
    "                          for aspect in self.aspects_list]\n",
    "        # ! DEBUG\n",
    "        # print(text)\n",
    "        # print(similarities)\n",
    "        # ~ DEBUG\n",
    "        for similarity in similarities:\n",
    "            if similarity[1] > self.min_similarity:\n",
    "                aspects.append(similarity[0])\n",
    "        return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d031d1ac-301a-4d44-b498-7072040c9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = MethodSimilarity(tokenizer=\"distiluse\", min_similarity=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8e0eb18-bd36-4448-bd4e-3db056193f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Фильмы',\n",
       " 'Материал, информация, темы',\n",
       " 'Эссе',\n",
       " 'Тесты',\n",
       " 'Онлайн-курс',\n",
       " 'Игры, интерактивность',\n",
       " 'Презентации',\n",
       " 'Домашняя работа',\n",
       " 'Доклады',\n",
       " 'Лекции',\n",
       " 'Задания, задачи',\n",
       " 'Литература, учебники',\n",
       " 'Зачет, экзамен',\n",
       " 'Проекты',\n",
       " 'Видео-уроки',\n",
       " 'Выступления',\n",
       " 'Практики, семинары',\n",
       " 'Преподаватель',\n",
       " 'Баллы, оценки']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.process(\"Лекции были скучными\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cb8b67-1196-4394-b12d-22eab0e55b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('seninoseno/rubert-base-cased-sentiment-study-feedbacks-solyanka')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('seninoseno/rubert-base-cased-sentiment-study-feedbacks-solyanka', return_dict=True)\n",
    "\n",
    "seninoseno_labels_to_our = {\n",
    "    0: 1,\n",
    "    1: 2,\n",
    "    2: 3,\n",
    "}\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "    return seninoseno_labels_to_our[predicted[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6095fc6f-8662-474f-8ec1-3f37ceee3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForSequenceClassification\n",
    "# import torch\n",
    "\n",
    "# model_name = \"seninoseno/rubert-base-cased-sentiment-study-feedbacks-solyanka\"\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# # set device to GPU\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "# # put model on GPU (is done in-place)\n",
    "# model.to(device)\n",
    "\n",
    "# seninoseno_labels_to_our = {\n",
    "#     'NEUTRAL': 1,\n",
    "#     'POSITIVE': 2,\n",
    "#     'NEGATIVE': 3,\n",
    "# }\n",
    "\n",
    "# def predict_sentiment(text):\n",
    "#     encoding = tokenizer(text, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
    "#     # put data on GPU\n",
    "#     for k,v in encoding.items():\n",
    "#          encoding[k] = v.to(device)\n",
    "#     # forward pass\n",
    "#     outputs = model(**encoding)\n",
    "#     # get predicted class indices\n",
    "#     predicted_class_indices = outputs.logits.argmax(-1).tolist()\n",
    "#     # turn into actual class names\n",
    "#     predicted_classes = [model.config.id2label[label] for label in predicted_class_indices]\n",
    "#     return predicted_classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c36c334-45c5-4cb1-af09-cb6d3de650d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"Практики были отличными\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79271dd6-5ede-4012-8070-a4874b1c5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel\n",
    "\n",
    "def razdel_texta(text: str) -> list[str]:\n",
    "    return [_.text for _ in razdel.sentenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0784c59-1af9-46b8-8112-4d600d53e700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Это первое предложение.', 'А это второе.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razdel_texta(\"Это первое предложение. А это второе.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16e80229-11a1-487d-9172-cbbc4bfe6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, aspect) -> int:\n",
    "    sentences = razdel_texta(text)\n",
    "    for sentence in sentences:\n",
    "        found_aspects = search.process(sentence)\n",
    "        if aspect_to_readable_aspect[aspect] in found_aspects:\n",
    "            sentiment = predict_sentiment(sentence)\n",
    "            return sentiment\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f3c1e50-b017-40e4-8ef8-87ef1ec94e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2375/2375 [45:22<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# предиктим аспекты\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "#1750:\n",
    "#df_slice = dataset[1650:].sample(frac=1.0)\n",
    "df_slice = dataset.sample(frac=1.0)\n",
    "\n",
    "y_pred = []\n",
    "for s, a in tqdm(zip(df_slice[\"text\"], df_slice[\"aspect\"]), total=len(df_slice)):\n",
    "    y_pred.append(predict(s, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08b1677d-0fd9-4ed0-ae2d-f13d31b364c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PREDICTED_DIR = Path(\"../output/test-old-method-absa-accuracy\")\n",
    "OUTPUT_FILENAME = \"predicted.bin\"\n",
    "OUTPUT_PREDICTED_PATH = OUTPUT_PREDICTED_DIR / OUTPUT_FILENAME\n",
    "OUTPUT_PREDICTED_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a11386ed-f857-4fd4-953e-b225d95453fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и сохраняем в файл на будещее.\n",
    "with open(OUTPUT_PREDICTED_PATH, \"wb\") as f:\n",
    "    pickle.dump(y_pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9f6cf44-0ea8-4287-96ae-b9cef0039504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2375\n"
     ]
    }
   ],
   "source": [
    "# подгружаем запредикченые значения\n",
    "with open(OUTPUT_PREDICTED_PATH, \"rb\") as f:\n",
    "    y_pred = pickle.load(f)\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "656afd42-9219-4e74-9d04-4c99c5100da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2375\n"
     ]
    }
   ],
   "source": [
    "y_true = list(df_slice[\"label\"])\n",
    "print(len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d08531ab-c9d7-4851-847d-9318d26046b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1  0.41829607270292685\n",
      "Precision  0.3978856736731679\n",
      "Recall  0.4579162819967989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "print(\"F1 \", f1_score(y_true=y_true, y_pred=y_pred, average=\"macro\"))\n",
    "print(\"Precision \", precision_score(y_true=y_true, y_pred=y_pred, average=\"macro\"))\n",
    "print(\"Recall \", recall_score(y_true=y_true, y_pred=y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb6555-555f-4e4a-91fb-80a245e786d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15537956-8152-42ab-a6f8-be849ea84f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
