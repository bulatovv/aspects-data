{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad6cf1e-8502-4eba-83d6-debd578106c3",
   "metadata": {},
   "source": [
    "Задача: превратить дамп датасета Отзывуса (только тексты в виде csv файла) в пригодный для разметки csv файл.\n",
    "\n",
    "Файл должен быть формата\n",
    "\n",
    "```\n",
    "text;аспект1;аспект2;аспект3;...\n",
    "<Текст отзыва>;0|4;0|4;0|4;...\n",
    "```\n",
    "\n",
    "pd.NA - аспект не представлен ни в одном файле, 4 - представлен.<br>\n",
    "1-3 зарезервированы для эмоциональной окраски"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0bac94-db19-4a3d-8a03-6de8ddf95eb3",
   "metadata": {},
   "source": [
    "# Скачиваем дамп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9345baa4-be3e-4684-874c-5df509282a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c668c097-96d0-466e-b96f-7f3ddbc4fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIRECTORY = Path(\"../data/datasets\")\n",
    "ANNOTATED_ALL_DIRECTORY = Path(\"../data/otzyvus-annotated/annotated_files_all\")\n",
    "ANNOTATED_REAL_DIRECTORY = Path(\"../data/otzyvus-annotated/annotated_files_real\")\n",
    "ANNOTATED_AI_DIRECTORY = Path(\"../data/otzyvus-annotated/annotated_files_ai\")\n",
    "DATASETS_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "FEEDBACKS_CSV_URL = \"https://drive.google.com/uc?export=download&id=1J1mcl3Dy_9B1DdKXdVDJGqpHll4DakQR\"\n",
    "FEEDBACKS_CSV_DIR = DATASETS_DIRECTORY / \"feedbacks-2024-05-06.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a943df-42ed-455f-bca6-378d9715f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(FEEDBACKS_CSV_DIR):\n",
    "    response = requests.get(FEEDBACKS_CSV_URL)\n",
    "    open(FEEDBACKS_CSV_DIR, \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2d75e-4c60-4af1-8586-2b39b042b8aa",
   "metadata": {},
   "source": [
    "# Методы чистки текста и разбиения на предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c41282d3-bee2-4a30-94ae-e69be7b9b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def clean_text(text: str):\n",
    "    # Убираем ссылки\n",
    "    clean = re.sub(u'(http|ftp|https):\\/\\/[^ ]+', '', text)\n",
    "    # Убираем все неалфавитные символы кроме дефиса и апострофа\n",
    "    clean = re.sub(u'[^а-я^А-Я^\\w^\\-^\\']', ' ', clean)\n",
    "    # Убираем тире\n",
    "    clean = re.sub(u' - ', ' ', clean)\n",
    "    # Убираем дубликаты пробелов\n",
    "    clean = re.sub(u'\\s+', ' ', clean)\n",
    "    # Убираем пробелы в начале и в конце строки\n",
    "    clean = clean.strip().lower()\n",
    "    return clean\n",
    "\n",
    "def get_sentences(text: str):\n",
    "    # Токенизация\n",
    "    return nltk.sent_tokenize(text, language=\"russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6e165-6708-43be-89ff-70040f1b7cbd",
   "metadata": {},
   "source": [
    "# Подготовка csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88533f4d-3efe-495e-a8c5-506a95d5a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем аспекты из названий файлов\n",
    "labels = [f[:-4] for f in os.listdir(ANNOTATED_ALL_DIRECTORY) if os.path.isfile(ANNOTATED_ALL_DIRECTORY / f) and f[-4:] == \".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83a4f752-bf39-4daf-b98e-785120743c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e13b0a87-9fe6-4fe2-bbfb-462f760c5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv(FEEDBACKS_CSV_DIR, sep=\";\")\n",
    "texts = texts_df[\"text\"]\n",
    "texts_len = len(texts)\n",
    "# Итоговый словарь, где пока что на перес\n",
    "annotation_dict = {\"text\": texts}\n",
    "annotated_dict = {}\n",
    "for label in labels:\n",
    "    annotation_dict[label] = pd.Series([pd.NA] * texts_len)\n",
    "    with open(ANNOTATED_ALL_DIRECTORY / (label+\".txt\"), \"r\") as file:\n",
    "        annotated_dict[label] = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78e1eed9-2d48-4796-a020-2bab9eb01608",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in zip(range(texts_len), texts):\n",
    "    for label in annotated_dict:\n",
    "        intersection = set(get_sentences(text)) & set(annotated_dict[label])\n",
    "        if intersection:\n",
    "            annotation_dict[label][i] = 4\n",
    "            for sentence in intersection:\n",
    "                annotated_dict[label].remove(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89ce032e-aa04-47a5-b565-935d8e661eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(annotation_dict)\n",
    "result_df = result_df[result_df[\"мусор\"].isnull()].drop(\"мусор\", axis=1)\n",
    "result_df.to_csv(DATASETS_DIRECTORY / \"ready_for_annotation.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0602874-c626-4f6b-8e7f-76f5a65d92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in annotated_dict:\n",
    "    with open(ANNOTATED_AI_DIRECTORY / (label+\".txt\"), \"w\") as file:\n",
    "        file.write(\"\\n\".join(annotated_dict[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "592c9b26-f38c-4a70-8578-fa6bafe5fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(ANNOTATED_ALL_DIRECTORY):\n",
    "    with open(ANNOTATED_ALL_DIRECTORY / filename) as file:\n",
    "        sentences_all = set(file.read().split(\"\\n\"))\n",
    "    with open(ANNOTATED_AI_DIRECTORY / filename) as file:\n",
    "        sentences_real = set(file.read().split(\"\\n\"))\n",
    "    sentences_ai = sentences_all - sentences_real\n",
    "    with open(ANNOTATED_REAL_DIRECTORY / filename, \"w\") as file:\n",
    "        file.write(\"\\n\".join(sentences_ai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b05a1e-1b99-42d5-bb32-c45b04c4543c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
